import requests
import json
import time
import schedule
import random
from datetime import datetime

# ================= æ ¸å¿ƒé…ç½®åŒº =================
# 1. åˆšåˆšæå–çš„ Query ID (æ³¨æ„å¤§å°å†™ï¼)
# æ ¹æ®ä½ çš„æˆªå›¾ï¼Œè¿™é‡Œå¡«çš„æ˜¯å¤§å†™ F çš„ç‰ˆæœ¬ã€‚å¦‚æœæŠ¥é”™ 404ï¼Œè¯·å°è¯•æ”¹æˆå°å†™ f
CURRENT_QUERY_ID = "M1jEez78PEFVfbQLvlWMvQ"

# 2. ä½ çš„ Cookie å‡­è¯
MY_AUTH_TOKEN = "c3778b43e1705ad15fd2e8b683087db33fb3aa1e"
MY_CT0 = "368af3c63dffcc690f8557421437270654944077c8fdd21103da457e4225508284c606385efa8dd6b74c5463e87eb42c0c91b68620b1e1827e0c8e8eb1db381efcc70fdce615e3d0351dc886b27b0cf0"

# 3. ç›‘æ§ç›®æ ‡
TARGET_ACCOUNTS = [
    "lubi366", "connectfarm1", "wolfyxbt", "Crypto_He", "BroLeon", 
    "0xcryptowizard", "one_snowball", "yueya_eth", "qlonline", 
    "ai_9684xtpa", "cz_binance", "linwanwan823"
]

# 4. n8n åœ°å€
N8N_WEBHOOK_URL = "http://43.139.245.223:5678/webhook/6d6ea3d6-ba16-4d9d-9145-22425474ab48"

# 5. æ—¶é—´è®¾ç½®ï¼š16åˆ†é’Ÿä¸€è½®
CHECK_INTERVAL_MINUTES = 16 
# ============================================

last_seen_ids = {}

def get_latest_tweets():
    print(f"\n[{datetime.now().strftime('%H:%M:%S')}] === [Cookie ç™»å½•ç‰ˆ] å¼€å§‹æ£€æŸ¥ ===", flush=True)
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Authorization": "Bearer AAAAAAAAAAAAAAAAAAAAANRILgAAAAAAnNwIzUejRCOuH5E6I8xnZz4puTs%3D1Zv7ttfk8LF81IUq16cHjhLTvJu4FA33AGWWjCpTnA",
        "Content-Type": "application/json",
        "X-Csrf-Token": MY_CT0,
        "x-twitter-active-user": "yes",
        "x-twitter-auth-type": "OAuth2Session",
        "x-twitter-client-language": "en",
        "Cookie": f"auth_token={MY_AUTH_TOKEN}; ct0={MY_CT0}"
    }

    # åŠ¨æ€æ‹¼æ¥ URL
    url = f"https://x.com/i/api/graphql/{CURRENT_QUERY_ID}/SearchTimeline"

    for username in TARGET_ACCOUNTS:
        try:
            print(f"æ­£åœ¨æ£€æŸ¥: @{username} ...", end="", flush=True)
            
            # æ„é€ å‚æ•°
            params = {
                "variables": json.dumps({
                    "rawQuery": f"from:{username}",
                    "count": 5,
                    "querySource": "typed_query",
                    "product": "Latest"
                }),
                "features": json.dumps({
                    "responsive_web_graphql_exclude_directive_enabled": True,
                    "verified_phone_label_enabled": False,
                    "responsive_web_home_pinned_timelines_enabled": True,
                    "creator_subscriptions_tweet_preview_api_enabled": True,
                    "responsive_web_graphql_timeline_navigation_enabled": True,
                    "responsive_web_graphql_skip_user_profile_image_extensions_enabled": False,
                    "c9s_tweet_anatomy_moderation_enabled": False,
                    "tweet_fyp_is_dont_mention_me_view_enabled": True,
                    "responsive_web_edit_tweet_api_enabled": True,
                    "graphql_is_translatable_rweb_tweet_is_translatable_enabled": True,
                    "view_counts_everywhere_api_enabled": True,
                    "longform_notetweets_consumption_enabled": True,
                    "responsive_web_twitter_article_tweet_consumption_enabled": False,
                    "tweet_awards_web_tipping_enabled": False,
                    "freedom_of_speech_not_reach_fetch_enabled": True,
                    "standardized_nudges_misinfo": True,
                    "tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled": True,
                    "rweb_video_timestamps_enabled": True,
                    "longform_notetweets_rich_text_read_enabled": True,
                    "longform_notetweets_inline_media_enabled": True,
                    "responsive_web_media_download_video_enabled": False,
                    "responsive_web_enhance_cards_enabled": False
                })
            }
            
            response = requests.get(url, headers=headers, params=params, timeout=15)
            
            if response.status_code == 200:
                data = response.json()
                try:
                    # å°è¯•è§£æ
                    instructions = data['data']['search_by_raw_query']['search_timeline']['timeline']['instructions']
                    entries = []
                    for instr in instructions:
                        if instr['type'] == 'TimelineAddEntries':
                            entries = instr['entries']
                            break
                    
                    found_tweet = None
                    for entry in entries:
                        if 'tweet' in entry['entryId']: 
                            item_content = entry['content']['itemContent']['tweet_results']['result']
                            if 'legacy' in item_content:
                                found_tweet = item_content['legacy']
                            elif 'tweet' in item_content: 
                                found_tweet = item_content['tweet']['legacy']
                            if found_tweet:
                                break
                    
                    if found_tweet:
                        tweet_id = found_tweet['id_str']
                        full_text = found_tweet['full_text']
                        created_at = found_tweet['created_at']
                        
                        if username not in last_seen_ids:
                            last_seen_ids[username] = tweet_id
                            print(f" -> [åˆå§‹åŒ–] æœ€æ–° ID: {tweet_id}", flush=True)
                        elif last_seen_ids[username] != tweet_id:
                            print(f"\n  -> â˜… å‘ç°æ–°æ¨æ–‡ï¼æ¨é€ä¸­...", flush=True)
                            payload = {
                                "source": "twitter_monitor_auth",
                                "author": username,
                                "content_raw": full_text,
                                "link": f"https://twitter.com/{username}/status/{tweet_id}",
                                "tweet_id": tweet_id,
                                "timestamp": created_at
                            }
                            try:
                                requests.post(N8N_WEBHOOK_URL, json=payload, timeout=10)
                                print("  -> æ¨é€æˆåŠŸ âœ…", flush=True)
                                last_seen_ids[username] = tweet_id
                            except Exception as e:
                                print(f"  -> âŒ æ¨é€å¤±è´¥: {e}", flush=True)
                        else:
                            print(f" -> æ— æ›´æ–°", flush=True)
                    else:
                        print(" -> æœªæ‰¾åˆ°å†…å®¹ (å¯èƒ½è¢«è¿‡æ»¤)", flush=True)

                except Exception as e:
                    print(f" -> è§£æè·³è¿‡: {e}", flush=True)
            elif response.status_code == 404:
                print(" -> âŒ ID é”™è¯¯ (404)ï¼è¯·æ£€æŸ¥ QUERY_ID çš„å¤§å°å†™ï¼", flush=True)
                break 
            elif response.status_code == 401 or response.status_code == 403:
                print(" -> âŒ è®¤è¯å¤±è´¥ (Cookieå¤±æ•ˆ)", flush=True)
            elif response.status_code == 429:
                print(" -> âš ï¸ è®¿é—®é¢‘ç¹", flush=True)
            else:
                print(f" -> è¯·æ±‚å¤±è´¥: {response.status_code}", flush=True)

        except Exception as e:
            print(f" -> å¼‚å¸¸: {e}", flush=True)
            
        # è®¾ç½®ä¸º 8 åˆ° 12 ç§’çš„éšæœºç­‰å¾…
        sleep_time = random.uniform(8, 12)
        time.sleep(sleep_time)

    print(f"=== æœ¬è½®ç»“æŸï¼Œç­‰å¾… {CHECK_INTERVAL_MINUTES} åˆ†é’Ÿ ===\n", flush=True)

print("ğŸ”¥ [System] å¯åŠ¨...", flush=True)
get_latest_tweets()
schedule.every(CHECK_INTERVAL_MINUTES).minutes.do(get_latest_tweets)

while True:
    schedule.run_pending()
    time.sleep(1)
